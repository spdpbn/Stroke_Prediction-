# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jT5k4IU7ZG2jgBZX-IVSVy5TBF8lSB6g
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from dataprep.eda import plot
from dataprep.eda import plot_correlation, plot_missing
from dataprep.eda import *
import plotly.express as px
import plotly.figure_factory as ff
from collections import Counter
import warnings
from sklearn.model_selection import train_test_split
warnings.filterwarnings("ignore")
df = pd.read_csv('stroke_prediction.csv')

pd.set_option('display.max_columns', None)

print(df.head())
#Drop id column

df.drop(columns=['id'],inplace=True) 

print(df.head())
df.info()
df.describe()
df.isna

df.isnull().sum()
plot_missing(df)
#imputing the missing values using mean

df=df.fillna(np.mean(df['bmi']))
df.info()
import pandas_profiling as pp
pp.ProfileReport(df)
plot(df)

df
plot(df, 'bmi')

plot_correlation(df)



create_report(df)


sns.countplot(x="stroke", data=df)
plt.show()


plt.figure(figsize=(15,8))
sns.heatmap(df.corr())


# Convert Marrital Status, Residence and Gender into 0's and 1's
df['gender']=df['gender'].apply(lambda x : 1 if x=='Male' else 0) 
df["Residence_type"] = df["Residence_type"].apply(lambda x: 1 if x=="Urban" else 0)
df["ever_married"] = df["ever_married"].apply(lambda x: 1 if x=="Yes" else 0)




# Removing the observations that have smoking_status type unknown. 
df=df[df['smoking_status']!='Unknown']


df




# used One Hot encoding smoking_status, work_type
data_dummies = df[['smoking_status','work_type']]
data_dummies=pd.get_dummies(data_dummies)
df.drop(columns=['smoking_status','work_type'],inplace=True)


data_dummies



y = df['stroke']
df.drop(columns=['stroke'],inplace=True)
x=df.merge(data_dummies,left_index=True, right_index=True,how='left')


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=0)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Using logistic regression algorithm
from sklearn.linear_model import LogisticRegression
log = LogisticRegression()
log.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = log.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)


#using random forest algorithm
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)
forest.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = forest.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
#using support vector machine algorithm
from sklearn.svm import SVC
support = SVC()
support.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = support.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
#using knn algorithm
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
#Using decision tree algorithm
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
tree.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = tree.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
#using naive bayes algorithm
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = nb.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
#Using xgboostClassifier of tree class to use Decision Tree Algorithm
from xgboost import XGBClassifier 
xgboost = XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=100, gamma=0, 
min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005)
xgboost.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = xgboost.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
from sklearn.linear_model import SGDClassifier
SGD = SGDClassifier()
SGD.fit(X_train, y_train)
from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = SGD.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100
from sklearn.metrics import classification_report
print( classification_report(y_test, SGD.predict(X_test)) )

df = pd.read_csv('stroke_prediction.csv')

pd.set_option('display.max_columns', None)

print(df.head())

#Drop id column

df.drop(columns=['id'],inplace=True) 

print(df.head())

df.info()

df.describe()

df.isna

df.isnull().sum()

plot_missing(df)

#imputing the missing values using mean

df=df.fillna(np.mean(df['bmi']))
df.info()

import pandas_profiling as pp
pp.ProfileReport(df)

!pip install pandas_profiling --upgrade

plot(df)

df

plot(df, 'bmi')

plot_correlation(df)

create_report(df)

sns.countplot(x="stroke", data=df)
plt.show()

plt.figure(figsize=(15,8))
sns.heatmap(df.corr())

# Convert Marrital Status, Residence and Gender into 0's and 1's
df['gender']=df['gender'].apply(lambda x : 1 if x=='Male' else 0) 
df["Residence_type"] = df["Residence_type"].apply(lambda x: 1 if x=="Urban" else 0)
df["ever_married"] = df["ever_married"].apply(lambda x: 1 if x=="Yes" else 0)

# Removing the observations that have smoking_status type unknown. 
df=df[df['smoking_status']!='Unknown']

df



# used One Hot encoding smoking_status, work_type
data_dummies = df[['smoking_status','work_type']]
data_dummies=pd.get_dummies(data_dummies)
df.drop(columns=['smoking_status','work_type'],inplace=True)

data_dummies

y = df['stroke']
df.drop(columns=['stroke'],inplace=True)
x=df.merge(data_dummies,left_index=True, right_index=True,how='left')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=0)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Using logistic regression algorithm
from sklearn.linear_model import LogisticRegression
log = LogisticRegression()
log.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = log.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

#using random forest algorithm
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)
forest.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = forest.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

#using support vector machine algorithm
from sklearn.svm import SVC
support = SVC()
support.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = support.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

#using knn algorithm
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

#Using decision tree algorithm
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
tree.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = tree.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

#using naive bayes algorithm
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = nb.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

#Using xgboostClassifier of tree class to use Decision Tree Algorithm
from xgboost import XGBClassifier 
xgboost = XGBClassifier(max_depth=5, learning_rate=0.01, n_estimators=100, gamma=0, 
min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005)
xgboost.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = xgboost.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

from sklearn.linear_model import SGDClassifier
SGD = SGDClassifier()
SGD.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = SGD.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)*100

from sklearn.metrics import classification_report
print( classification_report(y_test, SGD.predict(X_test)) )